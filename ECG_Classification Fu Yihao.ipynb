{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECG_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNqGlBF1Ej_D",
        "outputId": "caa44f86-60c2-4ba7-969f-39bf145d3258"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from keras import models, layers, regularizers\n",
        "from keras.datasets import mnist\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        " \n",
        "# Download the dataset\n",
        "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\n",
        "raw_data = dataframe.values\n",
        "#print(dataframe.head())\n",
        "# The last element contains the labels\n",
        "labels = raw_data[:, -1]\n",
        " \n",
        "# The other data points are the electrocadriogram data\n",
        "data = raw_data[:, 0:-1]\n",
        " \n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=21)\n",
        " \n",
        "# Normalize to [0, 1]\n",
        "min_val = tf.reduce_min(train_data)\n",
        "max_val = tf.reduce_max(train_data)\n",
        " \n",
        "train_data = (train_data - min_val) / (max_val - min_val)\n",
        "test_data = (test_data - min_val) / (max_val - min_val)\n",
        "train_data = tf.cast(train_data, tf.float32)\n",
        "test_data = tf.cast(test_data, tf.float32)\n",
        " \n",
        "#use one hot code = output 2 dimension  [0. 1.] & [1. 0.]\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        " \n",
        " \n",
        "print(train_labels.shape)\n",
        " \n",
        "import time\n",
        " \n",
        "time_start=time.time()\n",
        " \n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(units=64, activation='relu',input_shape=(140*1,),kernel_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(layers.Dropout(0.01))\n",
        "model.add(layers.Dense(units=64, activation='relu', kernel_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(layers.Dropout(0.01))\n",
        "#softmax can better perform in classiffication\n",
        "model.add(layers.Dense(units=2, activation='softmax'))\n",
        "# compile model\n",
        "model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "# train the network, epochs=how many turn, batch_size=how much data every tarining turn\n",
        "model.fit(train_data, train_labels, epochs=30, batch_size=128, verbose=2)\n",
        " \n",
        "# model performance\n",
        "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
        "print(\"test_loss:\", test_loss, \"test_accuracy:\", test_accuracy)\n",
        "time_end=time.time()\n",
        "print('totally time cost',time_end-time_start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3998, 2)\n",
            "Epoch 1/30\n",
            "32/32 - 1s - loss: 0.6557 - accuracy: 0.7671\n",
            "Epoch 2/30\n",
            "32/32 - 0s - loss: 0.4534 - accuracy: 0.9075\n",
            "Epoch 3/30\n",
            "32/32 - 0s - loss: 0.3274 - accuracy: 0.9375\n",
            "Epoch 4/30\n",
            "32/32 - 0s - loss: 0.2635 - accuracy: 0.9432\n",
            "Epoch 5/30\n",
            "32/32 - 0s - loss: 0.2168 - accuracy: 0.9512\n",
            "Epoch 6/30\n",
            "32/32 - 0s - loss: 0.2030 - accuracy: 0.9495\n",
            "Epoch 7/30\n",
            "32/32 - 0s - loss: 0.1862 - accuracy: 0.9580\n",
            "Epoch 8/30\n",
            "32/32 - 0s - loss: 0.1777 - accuracy: 0.9590\n",
            "Epoch 9/30\n",
            "32/32 - 0s - loss: 0.1645 - accuracy: 0.9640\n",
            "Epoch 10/30\n",
            "32/32 - 0s - loss: 0.1549 - accuracy: 0.9672\n",
            "Epoch 11/30\n",
            "32/32 - 0s - loss: 0.1592 - accuracy: 0.9665\n",
            "Epoch 12/30\n",
            "32/32 - 0s - loss: 0.1555 - accuracy: 0.9675\n",
            "Epoch 13/30\n",
            "32/32 - 0s - loss: 0.1388 - accuracy: 0.9732\n",
            "Epoch 14/30\n",
            "32/32 - 0s - loss: 0.1510 - accuracy: 0.9697\n",
            "Epoch 15/30\n",
            "32/32 - 0s - loss: 0.1456 - accuracy: 0.9702\n",
            "Epoch 16/30\n",
            "32/32 - 0s - loss: 0.1438 - accuracy: 0.9692\n",
            "Epoch 17/30\n",
            "32/32 - 0s - loss: 0.1319 - accuracy: 0.9745\n",
            "Epoch 18/30\n",
            "32/32 - 0s - loss: 0.1408 - accuracy: 0.9720\n",
            "Epoch 19/30\n",
            "32/32 - 0s - loss: 0.1394 - accuracy: 0.9722\n",
            "Epoch 20/30\n",
            "32/32 - 0s - loss: 0.1331 - accuracy: 0.9740\n",
            "Epoch 21/30\n",
            "32/32 - 0s - loss: 0.1267 - accuracy: 0.9757\n",
            "Epoch 22/30\n",
            "32/32 - 0s - loss: 0.1331 - accuracy: 0.9735\n",
            "Epoch 23/30\n",
            "32/32 - 0s - loss: 0.1288 - accuracy: 0.9750\n",
            "Epoch 24/30\n",
            "32/32 - 0s - loss: 0.1293 - accuracy: 0.9755\n",
            "Epoch 25/30\n",
            "32/32 - 0s - loss: 0.1267 - accuracy: 0.9755\n",
            "Epoch 26/30\n",
            "32/32 - 0s - loss: 0.1265 - accuracy: 0.9742\n",
            "Epoch 27/30\n",
            "32/32 - 0s - loss: 0.1147 - accuracy: 0.9812\n",
            "Epoch 28/30\n",
            "32/32 - 0s - loss: 0.1169 - accuracy: 0.9805\n",
            "Epoch 29/30\n",
            "32/32 - 0s - loss: 0.1257 - accuracy: 0.9772\n",
            "Epoch 30/30\n",
            "32/32 - 0s - loss: 0.1172 - accuracy: 0.9782\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9830\n",
            "test_loss: 0.10853585600852966     test_accuracy: 0.9829999804496765\n",
            "totally time cost 2.7555625438690186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elhVN2Cp8M2a"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0URNDK9al1L3",
        "outputId": "5cdf0bc1-1cfb-4c14-c25d-921aff08348e"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import keras\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras import models, layers, regularizers\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense,Reshape\r\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras import layers, losses\r\n",
        "from tensorflow.keras.datasets import fashion_mnist\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.callbacks import ReduceLROnPlateau\r\n",
        "import time\r\n",
        "\r\n",
        "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\r\n",
        "raw_data = dataframe.values\r\n",
        "#print(dataframe.head())\r\n",
        "# The last element contains the labels\r\n",
        "labels = raw_data[:, -1]\r\n",
        "\r\n",
        "# The other data points are the electrocadriogram data\r\n",
        "data = raw_data[:, 0:-1]\r\n",
        "\r\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=21)\r\n",
        "\r\n",
        "# Normalize to [0, 1]\r\n",
        "min_val = tf.reduce_min(train_data)\r\n",
        "max_val = tf.reduce_max(train_data)\r\n",
        "\r\n",
        "train_data = (train_data - min_val) / (max_val - min_val)\r\n",
        "test_data = (test_data - min_val) / (max_val - min_val)\r\n",
        "train_data = tf.cast(train_data, tf.float32)\r\n",
        "test_data = tf.cast(test_data, tf.float32)\r\n",
        "#one hot code\r\n",
        "train_labels = to_categorical(train_labels)\r\n",
        "test_labels = to_categorical(test_labels)\r\n",
        "#column 3 : channel\r\n",
        "train_data=train_data[...,None]\r\n",
        "test_data=test_data[...,None]\r\n",
        "#print(train_data.shape)\r\n",
        "#print(train_labels.shape)\r\n",
        "print(train_labels)\r\n",
        "\r\n",
        "time_start=time.time()\r\n",
        "model=Sequential()\r\n",
        "#first convolution\r\n",
        "model.add(layers.Conv1D(filters=4,kernel_size=8,strides=1,padding=\"VALID\",activation='relu'))\r\n",
        "#first pooling\r\n",
        "#padding type : same , valid & full\r\n",
        "model.add(layers.MaxPool1D(pool_size=3,strides=2,padding=\"VALID\"))\r\n",
        "#kill 10% neruons\r\n",
        "model.add(layers.Dropout(rate=0.1))\r\n",
        "#second convolution\r\n",
        "model.add(layers.Conv1D(filters=16,kernel_size=8,strides=1,padding=\"VALID\",activation='relu'))\r\n",
        "#second polling\r\n",
        "model.add(layers.MaxPool1D(pool_size=3,strides=2,padding=\"VALID\"))\r\n",
        "model.add(layers.Dropout(rate=0.1))\r\n",
        "model.add(layers.Conv1D(filters=32, kernel_size=8, strides=1, padding='VALID', activation='relu'))\r\n",
        "#pooling type: avg & max\r\n",
        "model.add(layers.AvgPool1D(pool_size=3, strides=2, padding='VALID'))\r\n",
        "model.add(layers.Dropout(rate=0.1))\r\n",
        "model.add(layers.Conv1D(filters=64, kernel_size=8, strides=1, padding='VALID', activation='relu'))\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(units=128,activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(rate=0.1))\r\n",
        "#output unit =0 or 1\r\n",
        "model.add(layers.Dense(units=2,activation=\"softmax\"))\r\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\r\n",
        "model.fit(train_data, train_labels, epochs=30,batch_size=128,verbose=2)\r\n",
        "score = model.evaluate(test_data, test_labels, verbose=0)\r\n",
        "print('Test loss:', score[0])\r\n",
        "print('Test accuracy:', score[1]) # first is loss, second is [metrics]\r\n",
        "time_end=time.time()\r\n",
        "print('totally cost',time_end-time_start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3998, 140, 1)\n",
            "(3998, 2)\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "Epoch 1/30\n",
            "32/32 - 1s - loss: 0.6749 - accuracy: 0.5830\n",
            "Epoch 2/30\n",
            "32/32 - 1s - loss: 0.6364 - accuracy: 0.6346\n",
            "Epoch 3/30\n",
            "32/32 - 1s - loss: 0.4707 - accuracy: 0.7846\n",
            "Epoch 4/30\n",
            "32/32 - 1s - loss: 0.2747 - accuracy: 0.9042\n",
            "Epoch 5/30\n",
            "32/32 - 1s - loss: 0.1561 - accuracy: 0.9562\n",
            "Epoch 6/30\n",
            "32/32 - 1s - loss: 0.1268 - accuracy: 0.9687\n",
            "Epoch 7/30\n",
            "32/32 - 1s - loss: 0.1198 - accuracy: 0.9685\n",
            "Epoch 8/30\n",
            "32/32 - 1s - loss: 0.1008 - accuracy: 0.9732\n",
            "Epoch 9/30\n",
            "32/32 - 1s - loss: 0.0919 - accuracy: 0.9745\n",
            "Epoch 10/30\n",
            "32/32 - 1s - loss: 0.0910 - accuracy: 0.9750\n",
            "Epoch 11/30\n",
            "32/32 - 1s - loss: 0.0809 - accuracy: 0.9762\n",
            "Epoch 12/30\n",
            "32/32 - 1s - loss: 0.0764 - accuracy: 0.9762\n",
            "Epoch 13/30\n",
            "32/32 - 1s - loss: 0.0631 - accuracy: 0.9797\n",
            "Epoch 14/30\n",
            "32/32 - 1s - loss: 0.0593 - accuracy: 0.9822\n",
            "Epoch 15/30\n",
            "32/32 - 1s - loss: 0.0564 - accuracy: 0.9835\n",
            "Epoch 16/30\n",
            "32/32 - 1s - loss: 0.0588 - accuracy: 0.9850\n",
            "Epoch 17/30\n",
            "32/32 - 1s - loss: 0.0527 - accuracy: 0.9867\n",
            "Epoch 18/30\n",
            "32/32 - 1s - loss: 0.0510 - accuracy: 0.9865\n",
            "Epoch 19/30\n",
            "32/32 - 1s - loss: 0.0453 - accuracy: 0.9867\n",
            "Epoch 20/30\n",
            "32/32 - 1s - loss: 0.0493 - accuracy: 0.9872\n",
            "Epoch 21/30\n",
            "32/32 - 1s - loss: 0.0510 - accuracy: 0.9877\n",
            "Epoch 22/30\n",
            "32/32 - 1s - loss: 0.0396 - accuracy: 0.9900\n",
            "Epoch 23/30\n",
            "32/32 - 1s - loss: 0.0439 - accuracy: 0.9885\n",
            "Epoch 24/30\n",
            "32/32 - 1s - loss: 0.0436 - accuracy: 0.9877\n",
            "Epoch 25/30\n",
            "32/32 - 1s - loss: 0.0414 - accuracy: 0.9902\n",
            "Epoch 26/30\n",
            "32/32 - 1s - loss: 0.0388 - accuracy: 0.9897\n",
            "Epoch 27/30\n",
            "32/32 - 1s - loss: 0.0402 - accuracy: 0.9877\n",
            "Epoch 28/30\n",
            "32/32 - 1s - loss: 0.0361 - accuracy: 0.9890\n",
            "Epoch 29/30\n",
            "32/32 - 1s - loss: 0.0390 - accuracy: 0.9892\n",
            "Epoch 30/30\n",
            "32/32 - 1s - loss: 0.0389 - accuracy: 0.9887\n",
            "Test loss: 0.04918200150132179\n",
            "Test accuracy: 0.9890000224113464\n",
            "totally cost 20.909254550933838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNV1K5LyIyjU",
        "outputId": "9bc1c028-c5bd-45c9-953a-90db90aeca9c"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import keras\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras import models, layers, regularizers\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras import layers, losses\r\n",
        "from tensorflow.keras.datasets import fashion_mnist\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.callbacks import ReduceLROnPlateau\r\n",
        "import time\r\n",
        "\r\n",
        "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\r\n",
        "raw_data = dataframe.values\r\n",
        "#print(dataframe.head())\r\n",
        "# The last element contains the labels\r\n",
        "labels = raw_data[:, -1]\r\n",
        "\r\n",
        "# The other data points are the electrocadriogram data\r\n",
        "data = raw_data[:, 0:-1]\r\n",
        "\r\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=21)\r\n",
        "\r\n",
        "# Normalize to [0, 1]\r\n",
        "min_val = tf.reduce_min(train_data)\r\n",
        "max_val = tf.reduce_max(train_data)\r\n",
        "\r\n",
        "train_data = (train_data - min_val) / (max_val - min_val)\r\n",
        "test_data = (test_data - min_val) / (max_val - min_val)\r\n",
        "train_data = tf.cast(train_data, tf.float32)\r\n",
        "test_data = tf.cast(test_data, tf.float32)\r\n",
        "\r\n",
        "train_labels = to_categorical(train_labels)\r\n",
        "test_labels = to_categorical(test_labels)\r\n",
        "train_data=train_data[...,None]\r\n",
        "test_data=test_data[...,None]\r\n",
        "\r\n",
        "time_start=time.time()\r\n",
        "\r\n",
        "model=Sequential()\r\n",
        "model.add(LSTM(64, return_sequences=True,input_shape=(140,1)))   \r\n",
        "model.add(LSTM(64, return_sequences=True))  \r\n",
        "model.add(LSTM(64))  \r\n",
        "model.add(Dense(2, activation='softmax'))\r\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\r\n",
        "model.fit(train_data, train_labels, epochs=30,batch_size=128,verbose=2)\r\n",
        "score = model.evaluate(test_data, test_labels, verbose=0)\r\n",
        "print('Test loss:', score[0])\r\n",
        "print('Test accuracy:', score[1])\r\n",
        "time_end=time.time()\r\n",
        "time_cost=time_end-time_start\r\n",
        "print('total time cost=',time_cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "32/32 - 15s - loss: 0.6046 - accuracy: 0.6698\n",
            "Epoch 2/30\n",
            "32/32 - 11s - loss: 0.1085 - accuracy: 0.9737\n",
            "Epoch 3/30\n",
            "32/32 - 11s - loss: 0.0753 - accuracy: 0.9787\n",
            "Epoch 4/30\n",
            "32/32 - 11s - loss: 0.0694 - accuracy: 0.9817\n",
            "Epoch 5/30\n",
            "32/32 - 11s - loss: 0.0606 - accuracy: 0.9827\n",
            "Epoch 6/30\n",
            "32/32 - 11s - loss: 0.0545 - accuracy: 0.9847\n",
            "Epoch 7/30\n",
            "32/32 - 11s - loss: 0.0638 - accuracy: 0.9812\n",
            "Epoch 8/30\n",
            "32/32 - 11s - loss: 0.0501 - accuracy: 0.9862\n",
            "Epoch 9/30\n",
            "32/32 - 11s - loss: 0.0470 - accuracy: 0.9862\n",
            "Epoch 10/30\n",
            "32/32 - 11s - loss: 0.0416 - accuracy: 0.9877\n",
            "Epoch 11/30\n",
            "32/32 - 11s - loss: 0.0486 - accuracy: 0.9847\n",
            "Epoch 12/30\n",
            "32/32 - 11s - loss: 0.0428 - accuracy: 0.9882\n",
            "Epoch 13/30\n",
            "32/32 - 11s - loss: 0.0383 - accuracy: 0.9890\n",
            "Epoch 14/30\n",
            "32/32 - 11s - loss: 0.0377 - accuracy: 0.9897\n",
            "Epoch 15/30\n",
            "32/32 - 11s - loss: 0.0418 - accuracy: 0.9897\n",
            "Epoch 16/30\n",
            "32/32 - 11s - loss: 0.0374 - accuracy: 0.9902\n",
            "Epoch 17/30\n",
            "32/32 - 11s - loss: 0.0370 - accuracy: 0.9902\n",
            "Epoch 18/30\n",
            "32/32 - 11s - loss: 0.0368 - accuracy: 0.9900\n",
            "Epoch 19/30\n",
            "32/32 - 11s - loss: 0.0348 - accuracy: 0.9907\n",
            "Epoch 20/30\n",
            "32/32 - 11s - loss: 0.0317 - accuracy: 0.9917\n",
            "Epoch 21/30\n",
            "32/32 - 12s - loss: 0.0327 - accuracy: 0.9922\n",
            "Epoch 22/30\n",
            "32/32 - 11s - loss: 0.0327 - accuracy: 0.9915\n",
            "Epoch 23/30\n",
            "32/32 - 11s - loss: 0.0314 - accuracy: 0.9920\n",
            "Epoch 24/30\n",
            "32/32 - 11s - loss: 0.0335 - accuracy: 0.9912\n",
            "Epoch 25/30\n",
            "32/32 - 11s - loss: 0.0416 - accuracy: 0.9877\n",
            "Epoch 26/30\n",
            "32/32 - 11s - loss: 0.0352 - accuracy: 0.9892\n",
            "Epoch 27/30\n",
            "32/32 - 11s - loss: 0.0299 - accuracy: 0.9920\n",
            "Epoch 28/30\n",
            "32/32 - 11s - loss: 0.0412 - accuracy: 0.9890\n",
            "Epoch 29/30\n",
            "32/32 - 11s - loss: 0.0348 - accuracy: 0.9915\n",
            "Epoch 30/30\n",
            "32/32 - 11s - loss: 0.0314 - accuracy: 0.9920\n",
            "Test loss: 0.033507540822029114\n",
            "Test accuracy: 0.9900000095367432\n",
            "total time cost= 343.68946528434753\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}